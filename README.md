# Udacity-DAND-Projects
## Project 1: Weather Trend Analysis

**Summary:**  This project is to study the global weather trend as well as a local cityâ€™s weather trend. Data will be extracted from the given database of Udacity using SQL, and loaded to Kaggle jupyter notebook for further exploratory analysis with Python data manipulation and visualization package. 

**Tools:**  SQL, Python (pandas, matplotlib, seaborn)

## Project 2: Investigate A Dataset

**Summary:**  This project is to investigate the IMDb dataset, apply data wrangling techniques to clean data and conduct exploratory data analysis, trying to answer questions such as how genres popularity has changed over time and how different factors affect a movie's revenue.

**Tools:**  Python (pandas, numpy, matplotlib, seaborn)

## Project 3: Analyze AB Test

**Summary:**  This project is to analyze the results of an A/B test run by an e-commerce website. The analysis helps the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.

**Tools:**  Python (pandas, numpy, statsmodels, random, matplotlib)

## Project 4: Analyze Dog Ratings @WeRateDogs

**Summary:**  This project is about data wrangling and visual analysis of data from the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. WeRateDogs has over 4 million followers and has received international media coverage. 

The dataset is composed of a Twitter archive file in .csv format, a .tsv file hosted on Udacity's server, and JSON data queried using Python's Tweepy library from Twitter API. The Jupyter notebook demonstrates the detailed process to gather, assess and clean data. The wrangle report provides a brief description of the steps taken during the data wrangling process. The act report provides insights of the dog ratings tweet data using visualization techniques.

**Tools:**  Python (pandas, numpy, seaborn, matplotlib, requests, os, tweepy, json)

## Project 5: Study of U.S. Flight Delays in 2008

**Summary:**  This project is to study the flight delays data and study the relationships between flight delays and various factors such as carrier, airport, flight time as well as flight distance.

The dataset for this project reports flights in the United States during the year of 2008 with 7,009,728 original records in total, including carriers, airports, arrival and departure delays as well as flight cancellations. After preliminary data wrangling, I added a few data features and removed unusable data records. As a result, the dataset now has 6,753,922 flight records with 32 features. 

**Tools:**  Python (pandas, numpy, seaborn, matplotlib)
